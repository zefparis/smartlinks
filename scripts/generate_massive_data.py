#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de g√©n√©ration massive de donn√©es pour SmartLinks Analytics
Optimis√© pour Windows avec gestion robuste des paths et encodage
"""

import sys
import os
import random
import time
from datetime import datetime, timedelta
from pathlib import Path

# Ajouter le r√©pertoire racine au path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from src.soft.db import SessionLocal, engine
    from src.soft.models import Base, Offer, Segment, Creator, Click, Conversion
except ImportError as e:
    print(f"‚ùå Erreur d'import: {e}")
    print("V√©rifiez que vous √™tes dans le bon r√©pertoire et que les d√©pendances sont install√©es")
    sys.exit(1)


def clean_database(db):
    """Nettoie compl√®tement la base de donn√©es"""
    print("üßπ Nettoyage de la base de donn√©es...")
    try:
        # Ordre important pour respecter les contraintes de cl√©s √©trang√®res
        db.execute('DELETE FROM conversions')
        db.execute('DELETE FROM clicks')
        db.execute('DELETE FROM creators')
        db.execute('DELETE FROM segments')
        db.execute('DELETE FROM offers')
        db.commit()
        print("   ‚úÖ Base nettoy√©e")
    except Exception as e:
        print(f"   ‚ùå Erreur lors du nettoyage: {e}")
        db.rollback()
        raise


def create_base_data(db):
    """Cr√©e les donn√©es de base (offres, segments, cr√©ateurs)"""
    print("üìä Cr√©ation des donn√©es de base...")
    
    # Cr√©er les offres
    offers_data = [
        ('gaming_premium', 'Gaming App Premium'),
        ('finance_pro', 'Finance Trading Pro'),
        ('ecommerce_plus', 'E-commerce Platform Plus'),
        ('fitness_tracker', 'Fitness Tracker Pro'),
        ('crypto_exchange', 'Crypto Exchange Pro'),
    ]
    
    offers = []
    for offer_id, name in offers_data:
        offer = Offer(
            offer_id=offer_id,
            name=name,
            url=f'https://{offer_id}.example.com',
            incent_ok=1,
            cap_day=2000,
            geo_allow='ALL',
            status='on'
        )
        offers.append(offer)
        db.add(offer)
    
    db.commit()
    print(f"   ‚úÖ {len(offers)} offres cr√©√©es")
    
    # Cr√©er les segments (geo + device)
    geos = ['US', 'UK', 'DE', 'FR', 'CA', 'AU', 'ES', 'IT', 'NL', 'SE']
    devices = ['mobile', 'desktop', 'tablet']
    
    segments = []
    for geo in geos:
        for device in devices:
            segment = Segment(
                segment_id=f'seg_{geo.lower()}_{device}',
                geo=geo,
                device=device
            )
            segments.append(segment)
            db.add(segment)
    
    db.commit()
    print(f"   ‚úÖ {len(segments)} segments cr√©√©s")
    
    # Cr√©er les cr√©ateurs
    creators = []
    for i in range(15):
        creator = Creator(
            creator_id=f'creator_{i+1:03d}',
            q=random.uniform(0.7, 0.9),
            hard_cap_eur=random.uniform(50.0, 200.0),
            last_seen=int(time.time())
        )
        creators.append(creator)
        db.add(creator)
    
    db.commit()
    print(f"   ‚úÖ {len(creators)} cr√©ateurs cr√©√©s")
    
    return offers, segments, creators, geos, devices


def generate_massive_clicks(db, offers, segments, creators, geos, devices, days=30, volume='high'):
    """G√©n√®re des clics massifs sur la p√©riode sp√©cifi√©e"""
    print(f"üöÄ G√©n√©ration de clics massifs ({days} jours, volume: {volume})...")
    
    # D√©finir le volume selon le param√®tre
    if volume == 'low':
        base_daily_clicks = (800, 1500)
    elif volume == 'medium':
        base_daily_clicks = (1500, 3000)
    elif volume == 'high':
        base_daily_clicks = (3000, 6000)
    else:  # ultra
        base_daily_clicks = (5000, 10000)
    
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    
    click_id = 1
    conv_id = 1
    total_clicks = 0
    total_conversions = 0
    total_revenue = 0
    
    for day in range(days):
        current_date = start_date + timedelta(days=day)
        base_ts = int(current_date.timestamp())
        
        # Volume progressif (plus r√©cent = plus d'activit√©)
        progress_factor = (day / days) * 0.5 + 0.75  # Entre 0.75 et 1.25
        daily_clicks = int(random.randint(*base_daily_clicks) * progress_factor)
        
        # Batch pour optimiser les insertions
        clicks_batch = []
        convs_batch = []
        
        for _ in range(daily_clicks):
            ts = base_ts + random.randint(0, 86400)
            geo = random.choice(geos)
            device = random.choice(devices)
            
            # Cr√©er le clic
            click = Click(
                click_id=f'click_{click_id:08d}',
                ts=ts,
                creator_id=random.choice(creators).creator_id,
                slug=f'link_{random.randint(1, 2000)}',
                segment_id=f'seg_{geo.lower()}_{device}',
                geo=geo,
                device=device,
                fp=f'fp_{random.randint(1000000, 9999999)}',
                valid_final=1,
                risk=random.uniform(0.1, 0.3),
                offer_id=random.choice(offers).offer_id
            )
            clicks_batch.append(click)
            total_clicks += 1
            
            # 12-18% de conversions selon le geo
            conversion_rate = 0.15
            if geo in ['US', 'UK', 'CA']:
                conversion_rate = 0.18
            elif geo in ['DE', 'FR', 'NL']:
                conversion_rate = 0.16
            elif geo in ['ES', 'IT']:
                conversion_rate = 0.12
            
            if random.random() < conversion_rate:
                # Revenus variables selon geo et device
                base_revenue = random.uniform(5.0, 25.0)
                if geo in ['US', 'UK']:
                    base_revenue *= 1.5
                if device == 'desktop':
                    base_revenue *= 1.2
                elif device == 'tablet':
                    base_revenue *= 1.1
                
                conv = Conversion(
                    id=f'conv_{conv_id:08d}',
                    ts=ts + random.randint(300, 3600),  # Conversion entre 5min et 1h apr√®s
                    click_id=click.click_id,
                    offer_id=click.offer_id,
                    revenue=round(base_revenue, 2),
                    status='approved'
                )
                convs_batch.append(conv)
                total_conversions += 1
                total_revenue += base_revenue
                conv_id += 1
            
            click_id += 1
        
        # Insertion par batch pour optimiser les performances
        db.add_all(clicks_batch)
        db.add_all(convs_batch)
        db.commit()
        
        # Log du progr√®s
        if day % 5 == 0 or day == days - 1:
            print(f"   Jour {day+1:2d}: {daily_clicks:4d} clics, {len(convs_batch):3d} conversions")
    
    print(f"")
    print(f"üéâ G√âN√âRATION TERMIN√âE!")
    print(f"üìä Statistiques finales:")
    print(f"   ‚îú‚îÄ Clics totaux: {total_clicks:,}")
    print(f"   ‚îú‚îÄ Conversions: {total_conversions:,}")
    print(f"   ‚îú‚îÄ Revenus: ‚Ç¨{total_revenue:,.2f}")
    print(f"   ‚îî‚îÄ Taux conversion: {(total_conversions/total_clicks*100):.1f}%")
    
    return total_clicks, total_conversions, total_revenue


def verify_data(db):
    """V√©rifie que les donn√©es ont √©t√© correctement g√©n√©r√©es"""
    print("üîç V√©rification des donn√©es g√©n√©r√©es...")
    
    try:
        # Compter les donn√©es
        clicks_count = db.query(Click).count()
        conversions_count = db.query(Conversion).count()
        segments_count = db.query(Segment).count()
        offers_count = db.query(Offer).count()
        creators_count = db.query(Creator).count()
        
        print(f"üìä Donn√©es en base:")
        print(f"   ‚îú‚îÄ Clics: {clicks_count:,}")
        print(f"   ‚îú‚îÄ Conversions: {conversions_count:,}")
        print(f"   ‚îú‚îÄ Segments: {segments_count}")
        print(f"   ‚îú‚îÄ Offres: {offers_count}")
        print(f"   ‚îî‚îÄ Cr√©ateurs: {creators_count}")
        
        # V√©rifier les segments avec donn√©es
        segment_stats = db.execute('''
            SELECT 
                s.segment_id,
                s.geo,
                s.device,
                COUNT(c.click_id) as clicks,
                COUNT(conv.id) as conversions
            FROM segments s
            LEFT JOIN clicks c ON s.segment_id = c.segment_id
            LEFT JOIN conversions conv ON c.click_id = conv.click_id AND conv.status = 'approved'
            GROUP BY s.segment_id, s.geo, s.device
            HAVING COUNT(c.click_id) > 0
            ORDER BY clicks DESC
            LIMIT 8
        ''').fetchall()
        
        print(f"")
        print(f"üåç Top segments avec donn√©es:")
        for row in segment_stats:
            segment_id, geo, device, clicks, conversions = row
            conv_rate = (conversions / clicks * 100) if clicks > 0 else 0
            print(f"   - {segment_id}: {clicks:,} clics, {conversions} conv ({conv_rate:.1f}%)")
        
        print(f"")
        print(f"‚úÖ Donn√©es pr√™tes pour le dashboard Analytics!")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la v√©rification: {e}")
        return False


def main():
    """Fonction principale"""
    import argparse
    
    parser = argparse.ArgumentParser(description='G√©n√©ration massive de donn√©es pour SmartLinks')
    parser.add_argument('--days', type=int, default=30, help='Nombre de jours de donn√©es (d√©faut: 30)')
    parser.add_argument('--volume', choices=['low', 'medium', 'high', 'ultra'], default='high', 
                       help='Volume de donn√©es (d√©faut: high)')
    parser.add_argument('--clean', action='store_true', help='Nettoyer la base avant g√©n√©ration')
    parser.add_argument('--verify-only', action='store_true', help='Seulement v√©rifier les donn√©es existantes')
    
    args = parser.parse_args()
    
    print("üîß G√âN√âRATION MASSIVE DE DONN√âES SMARTLINKS")
    print("=" * 60)
    print(f"Param√®tres: {args.days} jours, volume {args.volume}")
    if args.clean:
        print("Mode: nettoyage + g√©n√©ration")
    elif args.verify_only:
        print("Mode: v√©rification seulement")
    else:
        print("Mode: g√©n√©ration (sans nettoyage)")
    print("")
    
    # Cr√©er les tables si n√©cessaire
    Base.metadata.create_all(bind=engine)
    
    # Connexion √† la base
    db = SessionLocal()
    
    try:
        if args.verify_only:
            # Seulement v√©rifier
            verify_data(db)
            return
        
        if args.clean:
            # Nettoyer la base
            clean_database(db)
        
        # Cr√©er les donn√©es de base
        offers, segments, creators, geos, devices = create_base_data(db)
        
        # G√©n√©rer les clics massifs
        generate_massive_clicks(db, offers, segments, creators, geos, devices, 
                              days=args.days, volume=args.volume)
        
        # V√©rifier le r√©sultat
        verify_data(db)
        
        print("")
        print("üîÑ √âTAPES SUIVANTES:")
        print("   1. Red√©marrer le backend: python main.py")
        print("   2. Ouvrir le frontend: http://localhost:3000/analytics")
        print("   3. V√©rifier que toutes les donn√©es s'affichent")
        
    except Exception as e:
        print(f"‚ùå Erreur critique: {e}")
        import traceback
        traceback.print_exc()
        db.rollback()
        sys.exit(1)
    finally:
        db.close()


if __name__ == "__main__":
    main()
