#!/usr/bin/env python3
"""
OpenAI API Health Check - Diagnostic complet de connectivit√©
"""
import os
import time
import json
import requests
from datetime import datetime
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

class OpenAIHealthCheck:
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.model = os.getenv("OPENAI_MODEL", "gpt-4-turbo")
        self.base_url = "https://api.openai.com/v1"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
    def validate_api_key(self):
        """Valide le format de la cl√© API"""
        if not self.api_key:
            return False, "Cl√© API manquante"
        
        if not self.api_key.startswith("sk-"):
            return False, "Format de cl√© invalide (doit commencer par sk-)"
            
        if len(self.api_key) < 50:
            return False, "Cl√© API trop courte"
            
        return True, "Format de cl√© valide"
    
    def test_models_endpoint(self):
        """Test de l'endpoint /v1/models"""
        try:
            start_time = time.time()
            response = requests.get(
                f"{self.base_url}/models",
                headers=self.headers,
                timeout=10
            )
            latency = (time.time() - start_time) * 1000
            
            if response.status_code == 200:
                models_data = response.json()
                available_models = [m["id"] for m in models_data.get("data", [])]
                gpt4_models = [m for m in available_models if "gpt-4" in m]
                
                return True, {
                    "status": "OK",
                    "latency_ms": round(latency, 2),
                    "total_models": len(available_models),
                    "gpt4_models": gpt4_models[:5],  # Top 5 GPT-4 models
                    "target_model_available": self.model in available_models
                }
            else:
                return False, {
                    "status": "ERROR",
                    "http_code": response.status_code,
                    "error": response.text,
                    "latency_ms": round(latency, 2)
                }
                
        except requests.exceptions.Timeout:
            return False, {"status": "TIMEOUT", "error": "Timeout apr√®s 10s"}
        except requests.exceptions.ConnectionError:
            return False, {"status": "CONNECTION_ERROR", "error": "Impossible de se connecter √† OpenAI"}
        except Exception as e:
            return False, {"status": "EXCEPTION", "error": str(e)}
    
    def test_chat_completion(self):
        """Test d'une requ√™te de chat completion"""
        try:
            start_time = time.time()
            
            payload = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": "Tu es un assistant de test. R√©ponds bri√®vement."},
                    {"role": "user", "content": "Dis juste 'Test OK' si tu re√ßois ce message."}
                ],
                "max_tokens": 10,
                "temperature": 0
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=self.headers,
                json=payload,
                timeout=30
            )
            
            latency = (time.time() - start_time) * 1000
            
            if response.status_code == 200:
                data = response.json()
                choice = data.get("choices", [{}])[0]
                message = choice.get("message", {})
                
                return True, {
                    "status": "OK",
                    "model_used": data.get("model"),
                    "response": message.get("content", "").strip(),
                    "latency_ms": round(latency, 2),
                    "tokens_used": data.get("usage", {}).get("total_tokens", 0),
                    "finish_reason": choice.get("finish_reason")
                }
            else:
                return False, {
                    "status": "ERROR",
                    "http_code": response.status_code,
                    "error": response.text,
                    "latency_ms": round(latency, 2)
                }
                
        except requests.exceptions.Timeout:
            return False, {"status": "TIMEOUT", "error": "Timeout apr√®s 30s"}
        except requests.exceptions.ConnectionError:
            return False, {"status": "CONNECTION_ERROR", "error": "Impossible de se connecter √† OpenAI"}
        except Exception as e:
            return False, {"status": "EXCEPTION", "error": str(e)}
    
    def run_full_diagnostic(self):
        """Ex√©cute le diagnostic complet"""
        print("üîç OPENAI API HEALTH CHECK")
        print("=" * 50)
        
        timestamp = datetime.now().isoformat()
        print(f"Timestamp: {timestamp}")
        print(f"Mod√®le cible: {self.model}")
        print()
        
        # 1. Validation de la cl√©
        print("1. Validation de la cl√© API...")
        key_valid, key_msg = self.validate_api_key()
        print(f"   {key_msg}")
        
        if not key_valid:
            print("\n‚ùå HEALTHCHECK: FAILED - Cl√© API invalide")
            return
        
        # 2. Test de l'endpoint models
        print("\n2. Test de l'endpoint /v1/models...")
        models_ok, models_result = self.test_models_endpoint()
        
        if models_ok:
            print(f"   ‚úÖ OK - {models_result['total_models']} mod√®les disponibles")
            print(f"   Latence: {models_result['latency_ms']}ms")
            print(f"   Mod√®le cible disponible: {'‚úÖ' if models_result['target_model_available'] else '‚ùå'}")
            if models_result['gpt4_models']:
                print(f"   GPT-4 disponibles: {', '.join(models_result['gpt4_models'])}")
        else:
            print(f"   ‚ùå ERREUR: {models_result}")
            self._print_troubleshooting(models_result)
            return
        
        # 3. Test de chat completion
        print("\n3. Test de chat completion...")
        chat_ok, chat_result = self.test_chat_completion()
        
        if chat_ok:
            print(f"   ‚úÖ OK - R√©ponse re√ßue")
            print(f"   Mod√®le utilis√©: {chat_result['model_used']}")
            print(f"   Latence: {chat_result['latency_ms']}ms")
            print(f"   Tokens utilis√©s: {chat_result['tokens_used']}")
            print(f"   R√©ponse: '{chat_result['response']}'")
        else:
            print(f"   ‚ùå ERREUR: {chat_result}")
            self._print_troubleshooting(chat_result)
            return
        
        # R√©sum√© final
        print("\n" + "=" * 50)
        print("‚úÖ HEALTHCHECK: OK")
        print(f"Mod√®le: {chat_result.get('model_used', self.model)}")
        print(f"Latence moyenne: {round((models_result['latency_ms'] + chat_result['latency_ms']) / 2, 2)}ms")
        print(f"Timestamp: {timestamp}")
        print("Tous les tests sont pass√©s avec succ√®s!")
    
    def _print_troubleshooting(self, error_result):
        """Affiche les recommandations de troubleshooting"""
        print("\nüîß TROUBLESHOOTING:")
        
        status = error_result.get("status", "")
        http_code = error_result.get("http_code")
        
        if status == "CONNECTION_ERROR":
            print("   ‚Ä¢ V√©rifiez votre connexion internet")
            print("   ‚Ä¢ V√©rifiez les param√®tres proxy/firewall")
            print("   ‚Ä¢ Essayez: curl -I https://api.openai.com")
            
        elif status == "TIMEOUT":
            print("   ‚Ä¢ Connexion trop lente")
            print("   ‚Ä¢ Augmentez le timeout")
            print("   ‚Ä¢ V√©rifiez la latence r√©seau")
            
        elif http_code == 401:
            print("   ‚Ä¢ Cl√© API invalide ou expir√©e")
            print("   ‚Ä¢ V√©rifiez la cl√© dans votre compte OpenAI")
            print("   ‚Ä¢ R√©g√©n√©rez une nouvelle cl√© si n√©cessaire")
            
        elif http_code == 429:
            print("   ‚Ä¢ Quota d√©pass√© ou rate limit")
            print("   ‚Ä¢ Attendez quelques minutes")
            print("   ‚Ä¢ V√©rifiez votre usage sur platform.openai.com")
            
        elif http_code == 403:
            print("   ‚Ä¢ Acc√®s refus√©")
            print("   ‚Ä¢ V√©rifiez les permissions de votre cl√©")
            print("   ‚Ä¢ Contactez le support OpenAI")
            
        else:
            print(f"   ‚Ä¢ Erreur HTTP {http_code}")
            print("   ‚Ä¢ Consultez la documentation OpenAI")
            print("   ‚Ä¢ V√©rifiez les logs d√©taill√©s")

def main():
    checker = OpenAIHealthCheck()
    checker.run_full_diagnostic()

if __name__ == "__main__":
    main()
