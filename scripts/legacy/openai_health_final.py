#!/usr/bin/env python3
"""
OpenAI API Health Check - Diagnostic complet de connectivit√©
Compatible Windows avec gestion d'erreurs avanc√©e
"""
import os
import time
import requests
from datetime import datetime
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

def openai_health_check():
    """Diagnostic complet OpenAI API"""
    
    api_key = os.getenv('OPENAI_API_KEY')
    model = os.getenv('OPENAI_MODEL', 'gpt-4-turbo')
    
    print('üîç OPENAI API HEALTH CHECK')
    print('=' * 50)
    
    timestamp = datetime.now().isoformat()
    print(f'Timestamp: {timestamp}')
    print(f'Mod√®le cible: {model}')
    print()
    
    # 1. Validation de la cl√© API
    print('1. Validation de la cl√© API...')
    if not api_key:
        print('   ‚ùå Cl√© API manquante dans .env')
        print('   üîß TROUBLESHOOTING: Ajoutez OPENAI_API_KEY=sk-... dans .env')
        return False
        
    if not api_key.startswith('sk-'):
        print('   ‚ùå Format de cl√© invalide (doit commencer par sk-)')
        print('   üîß TROUBLESHOOTING: V√©rifiez le format sur platform.openai.com')
        return False
        
    if len(api_key) < 50:
        print('   ‚ùå Cl√© API trop courte')
        print('   üîß TROUBLESHOOTING: Cl√© probablement tronqu√©e')
        return False
        
    print('   ‚úÖ Format de cl√© valide')
    
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json',
        'User-Agent': 'SmartLinks-Autopilot/1.0'
    }
    
    # 2. Test de l'endpoint /v1/models
    print()
    print('2. Test de l\'endpoint /v1/models...')
    try:
        start_time = time.time()
        response = requests.get(
            'https://api.openai.com/v1/models', 
            headers=headers, 
            timeout=15
        )
        latency_models = (time.time() - start_time) * 1000
        
        if response.status_code == 200:
            models_data = response.json()
            available_models = [m['id'] for m in models_data.get('data', [])]
            gpt4_models = [m for m in available_models if 'gpt-4' in m]
            
            print(f'   ‚úÖ OK - {len(available_models)} mod√®les disponibles')
            print(f'   Latence: {round(latency_models, 2)}ms')
            print(f'   Mod√®le cible disponible: {"‚úÖ" if model in available_models else "‚ùå"}')
            
            if gpt4_models:
                print(f'   GPT-4 disponibles: {", ".join(gpt4_models[:5])}')
            else:
                print('   ‚ö†Ô∏è Aucun mod√®le GPT-4 trouv√©')
                
        elif response.status_code == 401:
            print('   ‚ùå ERREUR 401: Cl√© API invalide ou expir√©e')
            print('   üîß TROUBLESHOOTING:')
            print('     ‚Ä¢ V√©rifiez la cl√© sur platform.openai.com')
            print('     ‚Ä¢ R√©g√©n√©rez une nouvelle cl√© si n√©cessaire')
            print('     ‚Ä¢ V√©rifiez que le compte a des cr√©dits')
            return False
            
        elif response.status_code == 429:
            print('   ‚ùå ERREUR 429: Rate limit ou quota d√©pass√©')
            print('   üîß TROUBLESHOOTING:')
            print('     ‚Ä¢ Attendez quelques minutes')
            print('     ‚Ä¢ V√©rifiez votre usage sur platform.openai.com')
            print('     ‚Ä¢ Augmentez vos limites si n√©cessaire')
            return False
            
        else:
            print(f'   ‚ùå ERREUR HTTP {response.status_code}')
            print(f'   R√©ponse: {response.text[:200]}')
            return False
            
    except requests.exceptions.Timeout:
        print('   ‚ùå TIMEOUT apr√®s 15s')
        print('   üîß TROUBLESHOOTING:')
        print('     ‚Ä¢ V√©rifiez votre connexion internet')
        print('     ‚Ä¢ Testez: ping api.openai.com')
        print('     ‚Ä¢ V√©rifiez proxy/firewall')
        return False
        
    except requests.exceptions.ConnectionError:
        print('   ‚ùå ERREUR DE CONNEXION')
        print('   üîß TROUBLESHOOTING:')
        print('     ‚Ä¢ V√©rifiez votre connexion internet')
        print('     ‚Ä¢ V√©rifiez les param√®tres proxy Windows')
        print('     ‚Ä¢ Testez: curl -I https://api.openai.com')
        print('     ‚Ä¢ D√©sactivez temporairement antivirus/firewall')
        return False
        
    except Exception as e:
        print(f'   ‚ùå ERREUR INATTENDUE: {e}')
        return False
    
    # 3. Test de chat completion
    print()
    print('3. Test de chat completion...')
    try:
        start_time = time.time()
        
        payload = {
            'model': model,
            'messages': [
                {'role': 'system', 'content': 'Tu es un assistant de test. R√©ponds bri√®vement.'},
                {'role': 'user', 'content': 'Dis juste "Test OK" si tu re√ßois ce message.'}
            ],
            'max_tokens': 10,
            'temperature': 0
        }
        
        response = requests.post(
            'https://api.openai.com/v1/chat/completions',
            headers=headers,
            json=payload,
            timeout=45
        )
        
        latency_chat = (time.time() - start_time) * 1000
        
        if response.status_code == 200:
            data = response.json()
            choice = data.get('choices', [{}])[0]
            message = choice.get('message', {})
            usage = data.get('usage', {})
            
            print(f'   ‚úÖ OK - R√©ponse re√ßue')
            print(f'   Mod√®le utilis√©: {data.get("model")}')
            print(f'   Latence: {round(latency_chat, 2)}ms')
            print(f'   Tokens utilis√©s: {usage.get("total_tokens", 0)}')
            print(f'   R√©ponse: "{message.get("content", "").strip()}"')
            print(f'   Finish reason: {choice.get("finish_reason")}')
            
            # R√©sum√© final de succ√®s
            print()
            print('=' * 50)
            print('‚úÖ HEALTHCHECK: OK')
            print(f'Mod√®le: {data.get("model")}')
            print(f'Latence moyenne: {round((latency_models + latency_chat) / 2, 2)}ms')
            print(f'Timestamp: {timestamp}')
            print('Tous les tests sont pass√©s avec succ√®s!')
            print('OpenAI API est op√©rationnelle et pr√™te √† l\'usage.')
            return True
            
        elif response.status_code == 400:
            print('   ‚ùå ERREUR 400: Requ√™te malform√©e')
            error_data = response.json() if response.headers.get('content-type') == 'application/json' else {}
            print(f'   D√©tail: {error_data.get("error", {}).get("message", response.text[:100])}')
            return False
            
        elif response.status_code == 404:
            print(f'   ‚ùå ERREUR 404: Mod√®le "{model}" non trouv√©')
            print('   üîß TROUBLESHOOTING:')
            print('     ‚Ä¢ Utilisez un mod√®le disponible (gpt-4, gpt-4-turbo, gpt-3.5-turbo)')
            print('     ‚Ä¢ V√©rifiez l\'orthographe du nom du mod√®le')
            return False
            
        else:
            print(f'   ‚ùå ERREUR HTTP {response.status_code}')
            print(f'   R√©ponse: {response.text[:200]}')
            return False
            
    except requests.exceptions.Timeout:
        print('   ‚ùå TIMEOUT apr√®s 45s')
        print('   üîß TROUBLESHOOTING: Requ√™te trop lente, v√©rifiez la connexion')
        return False
        
    except Exception as e:
        print(f'   ‚ùå ERREUR Chat: {e}')
        return False

if __name__ == '__main__':
    success = openai_health_check()
    
    if not success:
        print()
        print('üîß RECOMMANDATIONS AVANC√âES WINDOWS:')
        print('1. Red√©marrez votre terminal en tant qu\'administrateur')
        print('2. V√©rifiez les variables d\'environnement: echo %OPENAI_API_KEY%')
        print('3. Testez la connectivit√©: nslookup api.openai.com')
        print('4. V√©rifiez les param√®tres proxy: netsh winhttp show proxy')
        print('5. D√©sactivez temporairement Windows Defender')
        print('6. Essayez avec un VPN si blocage g√©ographique')
        
    input('\nAppuyez sur Entr√©e pour quitter...')
